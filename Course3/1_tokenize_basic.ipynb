{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_tokenize_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNItx7XWuqHRTNXXvCjeFUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youngmi-Park/Coursera-DeepLearning.AI-TensorFlow-Developer/blob/main/Course3/1_tokenize_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블이 지정된 텍스트에 대해 학습된 텍스트를 이해하는 모델을 구축하는 방법을 배운다.\n",
        "\n",
        "이미지를 다룰 때 픽셀 값이 이미 숫자였기 때문에 이미지를 신경망에 공급하는 것이 상대적으로 쉬웠다. 하지만 텍스트는 어떻게 할까?\n",
        "\n",
        "예를 들어, 각 문자에 대해 문자 인코딩을 사용할 수 있다. 일반적인 단순 문자 인코딩은 ASCII(미국 표준 코드)가 있다. 하지만 이것은  단어의 의미가 문자로 인코딩되지 않는다. 따라서 문자만으로 신경망을 훈련시키는 것은 어려운 작업일 수 있다.\n",
        "\n",
        "그렇다면 단어에 값을 부여하고 해당 값을 네트워크 훈련에 사용해보자. 단어당 값을 가지고 있고, 그 값은 매번 같은 단어에 대해 동일하다.\n",
        "\n",
        "- I love my dog → 1 2 3 4\n",
        "- I love my cat → 1 2 3 5"
      ],
      "metadata": {
        "id": "sbJvOS1Fh-Av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API 사용해보기\n",
        "\n",
        "tensorflow와 keras는 단어를 인코딩하는 여러 가지 방법을 제공하지만 여기서는 tokenizer를 사용한다."
      ],
      "metadata": {
        "id": "eEmmcWDSrrGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "jt-7-8zdrKat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "            'I love my dog',\n",
        "            'I love my cat'\n",
        "]"
      ],
      "metadata": {
        "id": "Nh3gmM4QrYAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100) # Tokenizer instance 생성, num_word를 설정하면 토크나이저는 볼륨 기준 상위 100개 단어를 가져와 인코딩한다. \n",
        "tokenizer.fit_on_texts(sentences) # 데이터를 인코딩\n",
        "word_index = tokenizer.word_index # key(단어)-value(인코딩 값) 쌍을 포함하는 사전을 반환\n",
        "print(word_index) # I → i로 바뀜, tokenizer는 구두점 제거, 소문자화한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tXbsRverdCF",
        "outputId": "534ab134-6af9-4e18-eacc-4fda57205c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "            'I love my dog',\n",
        "            'I love my cat',\n",
        "            'You love my dog!'\n",
        "]"
      ],
      "metadata": {
        "id": "mYRmi7UArdIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100) # Tokenizer instance 생성, num_word를 설정하면 토크나이저는 볼륨 기준 상위 100개 단어를 가져와 인코딩한다. \n",
        "tokenizer.fit_on_texts(sentences) # 데이터를 인코딩\n",
        "word_index = tokenizer.word_index # key(단어)-value(인코딩 값) 쌍을 포함하는 사전을 반환\n",
        "print(word_index) # I → i로 바뀜, tokenizer는 공백 및 쉼표 구두점 제거, 대소문자를 구분하지 않는다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljri8NmktZm5",
        "outputId": "38df8828-9b71-402d-da7e-50634db55326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n"
          ]
        }
      ]
    }
  ]
}